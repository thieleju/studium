{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNQX4BiDq31s"
      },
      "source": [
        "<img src=\"https://www.th-ab.de/typo3conf/ext/th_ab/Resources/Public/assets/logo-th-ab.svg\" alt=\"TH-AB Logo\" width=\"200\"/>\n",
        "\n",
        "Prof. Dr. Möckel, Prof. Dr. Radke, Katharina Kuhnert\n",
        "\n",
        "Maschinelles Lernen Schwerpunkt Data Science<br>\n",
        "SoSe 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QlhS3GDq31w"
      },
      "source": [
        "# Übung 7: Convolutional Neural Networks (CNN) in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_264oM4dq31w"
      },
      "source": [
        "### Bibliotheken importieren und PyTorch Umgebung prüfen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZL5jnf9q31x"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# PyTorch\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    import torchmetrics\n",
        "except:\n",
        "    !pip install torch\n",
        "    !pip install torchvision\n",
        "    !pip install torchmetrics\n",
        "    import torch\n",
        "    import torchvision\n",
        "    import torchmetrics\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewsoGMUOq31y",
        "outputId": "c15bf336-4c6b-4228-a330-3c1334632f44"
      },
      "outputs": [],
      "source": [
        "# PyTorch Version überprüfen\n",
        "if (torch.__version__ < \"2.0.0\"):\n",
        "    raise Exception(\"Wrong PyTorch version\")\n",
        "else:\n",
        "    print(\"PyTorch Version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBrXqou2q31y"
      },
      "source": [
        "### Datasets aus MNIST laden und für maschinelles Lernen in Teildatensätze aufteilen \n",
        "* Training dataset\n",
        "* Non-training dataset (Validierung und Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuZKAtAgq31z"
      },
      "outputs": [],
      "source": [
        "# Dataset für Training\n",
        "ds_train = datasets.FashionMNIST(\n",
        "    root=\"data\", # Zielpfad für Datendownload\n",
        "    train=True, # Trainingsdaten laden\n",
        "    download=True,\n",
        "    transform=ToTensor(), # Transformiere Features (Bilddaten) zu Tensoren\n",
        "    target_transform=None # Keine Transformierung für Labels (Targets)\n",
        ")\n",
        "\n",
        "# Dataset für Validierung und Test\n",
        "ds_non_train = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # Keine Trainingsdaten laden\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aufgabe 1: Splitten Sie das ds_non_train Dataset:\n",
        "\n",
        "* 70% für Validierung (Modellvalidierung)\n",
        "* 30% für Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Splitting des non-train Dataset in:\n",
        "# 70% für Validierung (Modellvalidierung)\n",
        "# 30% für Tests\n",
        "total_count = len(ds_non_train)\n",
        "valid_count = \n",
        "test_count = \n",
        "\n",
        "# Splitte non-Train Dataset\n",
        "ds_valid, ds_test = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsVD73i2q310"
      },
      "source": [
        "### Aufgabe 2: Initiierung der DataLoader\n",
        "\n",
        "Das schrittweise Laden der Daten aus dem Datensatz in Abschnitten (batches) wird durch Datenloader realisiert.\n",
        "\n",
        "Legen Sie eine sinnvolle Batchgröße fest und erstellen Sie je eine Instanz \"DataLoader\" für die Validierung und Test:\n",
        "\n",
        "**Frage**: Welchen Einfluss hat die Batchgröße auf die Performanz des Modells?\n",
        "\n",
        "**Antwort**: Zu kleine oder zu große Batchgrößen (hier z.B. 2 bzw. 500) können die Performanz des Modells massiv reduzieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctqvYEZJq311",
        "outputId": "2b647916-a413-4970-c7ed-dc50d53403ed"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Nutze eine Batch-größe\n",
        "BATCH_SIZE = \n",
        "\n",
        "# Die DataLoader Klasse ermöglicht die Iteration durch die\n",
        "# Features eines Datasets.\n",
        "train_dataloader = DataLoader(ds_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "\n",
        "    # Zufällige Auswahl für jedes Batch\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# DataLoader für Validierung\n",
        "valid_dataloader = \n",
        "\n",
        "# DataLoader für Tests\n",
        "test_dataloader = \n",
        "\n",
        "# Ausgabe der Dataloader\n",
        "print(\"Größe train_dataloader:\", len(train_dataloader), \"Batches aus\", BATCH_SIZE)\n",
        "print(\"Größe valid_dataloader:\", len(valid_dataloader), \"Batches aus\", BATCH_SIZE)\n",
        "print(\"Größe test_dataloader:\", len(test_dataloader), \"Batches aus\", BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aufgabe 3: Lassen Sie sich die Labels aus dem Trainingsdataset ausgeben"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMnPzYpmq312"
      },
      "source": [
        "Da das Dataset für die Klassifikation von Ziffern gedacht ist entsprechen die Labels die Bezeichnungen der jeweiligen Ziffern. Die Klassen des Datasets lassen sich über das Property `.classes` ermitteln:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVDUshi6q313"
      },
      "outputs": [],
      "source": [
        "# Lade beliebiges Image aus Trainingsdataset\n",
        "image, label = ds_train[0]\n",
        "\n",
        "# Bestimme Datenformat\n",
        "color_channels = image.shape[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "\n",
        "# Lade Klassenbezeichnungen\n",
        "class_names = ds_train.classes\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aufgabe 4: Plotten Sie sich einige beliebige Bilder aus dem Trainingsdataset mit dem dazugehörigen Label:\n",
        "\n",
        "*Tip:* Nutzen Sie die Funktion .squeeze() um ein Bild für imshow() plotten zu lassen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setze den Seed für die Generierung von Zufallszahlen\n",
        "# für reproduzierbare Ergebnisse\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Plotte eine Matrix aus zufälligen Features und Labels des Datasets\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(ds_train), size=[1]).item()\n",
        "    img, label = ds_train[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M26PN7sNDjsE"
      },
      "source": [
        "## Einfaches CNN Modell\n",
        "\n",
        "### Aufgabe 5: Definieren Sie ein einfaches CNN\n",
        "\n",
        "Nutzen Sie die Kommentare als Orientierung welche Schritte im Modell durchlaufen werden sollen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K8jBkMtq313"
      },
      "outputs": [],
      "source": [
        "# Definiere CNN Modell\n",
        "class CNN_model(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        # Konstruktor der Basisklasse aufrufen\n",
        "        super().__init__()\n",
        "\n",
        "        # (1) Feature extraction:\n",
        "\n",
        "        # Konstruiere 1. Block (Input Conv2d -> ReLU -> Hidden Conv2d -> ReLU -> MaxPool2d)\n",
        "        self.block_1 = nn.Sequential(\n",
        "        )\n",
        "\n",
        "        # Konstruiere 2. Block (Hidden Conv2d -> ReLU -> Hidden Conv2d -> ReLU -> MaxPool2d)\n",
        "        self.block_2 = nn.Sequential(\n",
        "        )\n",
        "\n",
        "        # (2) Klassifizierer \n",
        "        self.classifier = nn.Sequential(\n",
        "            # Schritt 1: ReLU Aktivierungsfunktion\n",
        "            nn.ReLU(),\n",
        "            # Schritt 2: Umwandeln in Vektor\n",
        "            nn.Flatten(),\n",
        "            # Schritt 3: Verknüpfen von Hidden Layers mit Output\n",
        "            nn.Linear(in_features=hidden_units*7*7, out_features=output_shape)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Durchlaufe Block 1\n",
        "        x = self.block_1(x)\n",
        "        # Durchlaufe Block 2\n",
        "        x = self.block_2(x)\n",
        "        # Durchlaufe Klassifizierer\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FYw0p-Hq314"
      },
      "source": [
        "### Aufgabe 6: Erzeugen Sie eine Instanz vom Typ CNN_model als Modell. Vergleichen Sie die Modellperformance durch Änderung der Neuronenanzahl *hidden_units*:\n",
        "\n",
        "Festlegung der freien Parameter der Topologie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK7IATAgq314",
        "outputId": "3c9e93e8-ab48-4a75-b95f-a284a8bde9e8"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Erzeuge konkretes CNN Modell über Angabe der Parameter\n",
        "model_0 = CNN_model(\n",
        "    input_shape = ,\n",
        "\n",
        "    # Erzeuge Neuronen im Hidden Layer\n",
        "    hidden_units = ,\n",
        "\n",
        "    # Output-Layer des NN hat für jeden Klassenname ein Neuron\n",
        "    output_shape = \n",
        ")\n",
        "\n",
        "# Weise dem Modell die CPU zu.\n",
        "model_0.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwisWgS4q314"
      },
      "source": [
        "## Auswahl der Fehler- (Loss) bzw. Kostenfunktion (Cost) \n",
        "\n",
        "Verwendung der Kreuzentropie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTLRu-uGq315"
      },
      "outputs": [],
      "source": [
        "# Verwende Cross Entropy als Loss Funktion\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS4IXKEyq315"
      },
      "source": [
        "## Auswahl des Optimierers \n",
        "\n",
        "Angabe der den Optimierer betreffenden Hyperparameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aufgabe 7: Legen Sie eine sinnvolle Lernrate fest und vergleichen Sie wie diese die Modellperformanz beeinflusst."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYr0ToM2q315"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Lernrate\n",
        "LEARN_RATE = \n",
        "\n",
        "# Nutze Stochastic Gradient Descent als Optimierfunktion\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=LEARN_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avz6gp7Yq315"
      },
      "source": [
        "## Training des CNNs\n",
        "\n",
        "### Aufgabe 8: Welchen Einfluss hat die Anzahl der Epochen auf die Modellperformanz? Beginnen Sie mit Epoche 2 und erhöhen Sie diese."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70FdMi-Oq315",
        "outputId": "0de9bbd8-877a-48c1-917c-6d39794082f8"
      },
      "outputs": [],
      "source": [
        "# Initiierung der trainierbaren Parameter durch Zufallszahlen\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Hyperparameter Zahl der Epochen\n",
        "EPOCHS = 2\n",
        "\n",
        "# Merke Trainingfehler jeder Epoche für Plotting\n",
        "t_loss = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch:\", epoch, end=\"\\n-------\\n\")\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "\n",
        "        # Initiiere Modell in den Trainingsmodus (kein Training! Nur Modus setzen.)\n",
        "        model_0.train() \n",
        "\n",
        "        # NN 1. Anwendung des Modells auf Feature\n",
        "        y_pred = model_0(X)\n",
        "\n",
        "        # NN 2. Berechne loss für die aktuelle Batch\n",
        "        loss = loss_fn(y_pred, y)\n",
        "\n",
        "        # Merke Training loss über die aktuelle Epoche\n",
        "        train_loss += loss\n",
        "\n",
        "        # NN 3. Initiiere Optimizer Gradients auf 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # NN 4. Initiiere Rückwärtspropagation des Fehlers\n",
        "        loss.backward()\n",
        "\n",
        "        # NN 5. Optimiere\n",
        "        # Veränderung der Gewichte im Neuronalen Netz durch Zuweisung von Anteilen des Gesamtfehlers\n",
        "        optimizer.step()\n",
        "\n",
        "        # Ausgabe der bisher verarbeiteten Samples (Bild + Label)\n",
        "        if batch % 400 == 0:\n",
        "            print(\"Samples verarbeitet:\", batch * len(X), \"/\", len(train_dataloader.dataset))\n",
        "\n",
        "    # Ausgabe des durchschnittlichen Fehlers\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Speichere Trainingfehler\n",
        "    t_loss.append(train_loss)\n",
        "\n",
        "    print(\"Trainingsfehler: {:.5f}\".format(train_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3krmwk3q316"
      },
      "source": [
        "### Darstellung des Fehlers auf den Trainingsdaten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "kucT325dq316",
        "outputId": "5df551e2-8737-43f6-b089-5d54603a4a86"
      },
      "outputs": [],
      "source": [
        "# Lambda um Liste aus Tensoren in Liste aus Float umzuwandeln\n",
        "y_loss = lambda b : [x.tolist() for x in b]\n",
        "\n",
        "# Lambda um y-Werte für Plot zu erzeugen\n",
        "x_loss = lambda b : [ x for x in range(0, b)]\n",
        "\n",
        "plt.figure(figsize=(18, 8))\n",
        "plt.plot(x_loss(EPOCHS), y_loss(t_loss))\n",
        "plt.xlabel(\"Epoche\")\n",
        "plt.ylabel(\"Trainingsfehler\")\n",
        "plt.title(\"Trainingsverlauf\")\n",
        "plt.xticks(x_loss(EPOCHS))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju3mHRWjq316"
      },
      "source": [
        "\n",
        "## Beurteilung des Trainingserfolgs __Confusion matrix__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlUaXY5RzX6X"
      },
      "outputs": [],
      "source": [
        "y_test = []\n",
        "y_pred = []\n",
        "\n",
        "# Abschalten der Gradientenberechnung (nicht notwendig bei Evaluation)\n",
        "with torch.no_grad():\n",
        "    # Umschalten vom Training- in den Evaluationsmodus\n",
        "    # Alternative: model_0.train(False) \n",
        "    model_0.eval()\n",
        "\n",
        "    # loop for each data\n",
        "    for X,y in test_dataloader:\n",
        "        # STEP 1: forward pass\n",
        "        output = model_0(X)\n",
        "        # STEP 2: get predicted label\n",
        "        _, pred_label = torch.max(output, dim=1)\n",
        "        # STEP 3: append actual and predicted label\n",
        "        y_test += y.numpy().tolist()\n",
        "        y_pred += pred_label.numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_XVDBES2Ybo",
        "outputId": "6e836157-e8b3-4d14-fbdb-f8e336293cba"
      },
      "outputs": [],
      "source": [
        "print(y_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "8mpRC9IVzX2y",
        "outputId": "fc43319f-4b3a-43ba-c163-9db8c06218ac"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "plt.subplots(figsize=(10, 8))\n",
        "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\n",
        "ax.xaxis.set_ticks_position(\"top\")\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"Actual Label\")\n",
        "plt.title(\"Classification Results\", fontsize=16, fontweight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymYPeM3o4xg6"
      },
      "source": [
        "Aggregierte Fehlermetriken für einzelne Klassen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0Cqr2jC4a4r",
        "outputId": "52341996-5796-4e5a-fea2-fdadcf493ead"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, auc, roc_curve\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "juno",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
