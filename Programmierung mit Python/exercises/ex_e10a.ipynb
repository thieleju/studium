{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4", "collapsed_sections": ["u0Nx1TaFtvQ7"]}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "markdown", "source": ["# **\u00dcbung 10a** Programmierung mit Python mit Anwendungen aus dem Maschinellen Lernen"], "metadata": {"id": "tSeZ_kqott-k"}}, {"cell_type": "markdown", "source": ["## Aufgabe 1\n", "\n", "In dieser \u00dcbung sollen Sie auf ein konkretes Problem zur Datendom\u00e4ne aufmerksam gemacht werden. Diesem Problem begegnen Sie bei fast allen echten Problemen."], "metadata": {"id": "u0Nx1TaFtvQ7"}}, {"cell_type": "markdown", "source": ["**Aufgabe 1.1 (PyTorch)** | Laden Sie ihr Modell aus \u00dcbung 10."], "metadata": {"id": "PRg5k60Gyr4B"}}, {"cell_type": "code", "source": ["# Download 'custom_mnist.npz'\n", "!gdown 1jweRXd5KgPp-C-Wi9NF27E7JArZhwGpo"], "metadata": {"id": "JmLQv674xffj"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import torch\n", "model = torch.load('YOUR_MODEL.pt')"], "metadata": {"id": "pi2ufVDDuIJF"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.2 (PyTorch)** | Der folgende Code testet ihr Modell. Es wird auf verschiedenen Datens\u00e4tzen getestet. `easy` entspricht dabei den normalen Testdaten aus \u00dcbung 10. `medium` und `hard` sind augmentierte MNIST-Daten, die Parameter k\u00f6nnen dem Code entnommen werden. Des Weiteren gibt es einen `custom` Datensatz, dessen Herkunft eine weiter unten gegebene Webanwendung ist.\n", "```\n", "Beispiel:\n", "easy_acc_top1: 96.30\n", "easy_acc_top3: 99.71\n", "\n", "medium_acc_top1: 84.75\n", "medium_acc_top3: 97.39\n", "\n", "hard_acc_top1: 53.21\n", "hard_acc_top3: 78.32\n", "\n", "custom_top1: 75.54\n", "custom_top3: 90.16\n", "```\n", "\n", "Es sollte deutlich werden, dass die Performance auf anderen als dem `easy` Datensatz stark abf\u00e4llt."], "metadata": {"id": "mupDqIt1yzjp"}}, {"cell_type": "code", "source": ["# Testdaten herunterladen + Transformation anwenden\n", "import numpy as np\n", "from torch.utils.data import Dataset, DataLoader\n", "import torch.nn.functional as F\n", "from torchvision import datasets, transforms, utils\n", "from glob import glob\n", "\n", "BATCH_SIZE = 128\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "\n", "tt_easy = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.),\n", "                                ])\n", "\n", "tt_medium = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.),\n", "                                transforms.RandomAffine(degrees=5, translate=(0.1,0.1), scale=(0.9, 1.1)),\n", "                                transforms.ColorJitter(brightness=0.2, saturation=0.99)\n", "                                ])\n", "\n", "tt_hard = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.),\n", "                                transforms.RandomAffine(degrees=15, translate=(0.2,0.2), scale=(0.8, 1.2)),\n", "                                transforms.ColorJitter(brightness=0.2, saturation=0.99)\n", "                                ])\n", "\n", "target_transform = transforms.Compose([transforms.Lambda(lambda x:torch.LongTensor([x])),\n", "                                transforms.Lambda(lambda x: (F.one_hot(x, num_classes = 10).float().flatten(),x))\n", "                                ])\n", "\n", "class CustomMNIST(Dataset):\n", "    def __init__(self, data, transform=None, target_transform=None):\n", "        self.data = data\n", "        self.label = self.data['label']\n", "        self.imgs = self.data['imgs']\n", "        self.transform = transform\n", "        self.target_transform = target_transform\n", "\n", "    def __len__(self):\n", "        return len(self.label)\n", "\n", "    def __getitem__(self, idx):\n", "\n", "        img = self.imgs[idx]\n", "        label = self.label[idx]\n", "\n", "        if self.transform:\n", "            img = self.transform(img)\n", "\n", "        if self.target_transform:\n", "            label = self.target_transform(label)\n", "\n", "        return img, label\n", "\n", "\n", "custom_data =  np.load('custom_mnist.npz', allow_pickle=True)\n", "custom_loader = {\n", "   f:  DataLoader(CustomMNIST(custom_data[f].item(), transform=tt_easy, target_transform=target_transform), batch_size=BATCH_SIZE, shuffle=False) for f in custom_data.keys()\n", "}\n", "\n", "data_loaders = {\n", "    \"easy\": DataLoader(datasets.MNIST('./data_online', download=True, train=False, transform=tt_easy, target_transform=target_transform), batch_size=BATCH_SIZE, shuffle=False),\n", "    \"medium\": DataLoader(datasets.MNIST('./data_online', download=True, train=False, transform=tt_medium, target_transform=target_transform), batch_size=BATCH_SIZE, shuffle=False),\n", "    \"hard\": DataLoader(datasets.MNIST('./data_online', download=True, train=False, transform=tt_hard, target_transform=target_transform), batch_size=BATCH_SIZE, shuffle=False),\n", "    **custom_loader\n", "}\n", "\n", "contrib_full_results = {\n", "    \"easy\": 0.0,\n", "    \"medium\": 0.0,\n", "    \"hard\": 0.0,\n", "    **{ k:1.0 for k in data_loaders.keys() if k not in ['easy', 'medium', 'hard']}\n", "}\n", "\n", "full_results = {\n", "     k:{'c1': 0, 'c3': 0, 't': 0} for k in data_loaders.keys()\n", "} \n", "\n", "model = model.to(device)\n", "model.eval()\n", "\n", "full_correct_test = 0\n", "full_total_test = 0\n", "\n", "for k, dl in data_loaders.items():\n", "  for inputs_test, (target_test_oh, target_test) in dl:\n", "    inputs_test = inputs_test.to(device)\n", "    target_test_oh = target_test_oh.to(device)\n", "    target_test = target_test.to(device)\n", "    y_test = model(inputs_test)\n", "    a, target_pred = torch.max(y_test.data, 1)\n", "    b, target_pred_top3 = torch.topk(y_test.data, 3, 1, True, True)\n", "\n", "    full_results[k]['c1'] += (target_pred == target_test.flatten()).sum().item()\n", "    full_results[k]['c3'] += ((target_pred_top3[:][:,0] == target_test.flatten()) | (target_pred_top3[:][:,1] == target_test.flatten()) | (target_pred_top3[:][:,2] == target_test.flatten())).sum().item()\n", "    full_results[k]['t'] += target_test.size(0)\n", "\n", "\n", "\n", "  acc_test = 100.0 * full_results[k]['c1'] / full_results[k]['t']\n", "  acc_top3 = 100.0 * full_results[k]['c3'] / full_results[k]['t']\n", "\n", "  if 'px' not in k:\n", "    print(f'{k}_acc_top1: {acc_test:.2f}')\n", "    print(f'{k}_acc_top3: {acc_top3:.2f}\\n')\n", "\n", "c1 = 0\n", "c3 = 0\n", "t = 0\n", "for k in data_loaders.keys():\n", "  factor = contrib_full_results[k]\n", "  c1 += full_results[k]['c1'] * factor\n", "  c3 += full_results[k]['c3'] * factor\n", "  t += full_results[k]['t'] * factor\n", "\n", "facc_test = 100.0 * c1 / t\n", "facc_top3 = 100.0 * c3 / t\n", "\n", "print(f'custom_top1: {facc_test:.2f}')\n", "print(f'custom_top3: {facc_top3:.2f}')\n"], "metadata": {"id": "jCTEc-RHcYUn"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.3 (PyTorch)** | Durch die Datenmanipulation oder den selbst aufgezeichneten Daten, ver\u00e4ndert sich die Dom\u00e4ne der Daten. Auch wenn die Dom\u00e4nen auf den ersten Blick \u00e4hnlich erscheinen, sind trainierte Modelle oft so weit angepasst, dass sie keine gute Performance auf der neuen und unbekannten Dom\u00e4ne mehr liefern.\n", "\n", "\n", "Im folgenden k\u00f6nnen Sie drei Verfahren testen, um die Generalisierung auf unbekannte Daten zu erh\u00f6hen. Diese sind:\n", "- Bessere Architekturen\n", "- Vortrainiertes Modell verwenden + Fine-Tuning\n", "- Unbekannte/Neue Daten sammeln und neu trainieren\n", "\n", "\n", "Zun\u00e4chst ist eine kleine interaktive Anwendung gegeben. Wenn Sie die n\u00e4chste Zelle starten, k\u00f6nnen Sie auf diese \u00fcber den in der Ausgabe angegebenen Link zugreifen.\n", "\n", "`Beispiel: https://NUMERS-8000-colab.googleusercontent.com/`\n", "\n", "Die Website erlaubt Ihnen zu zeichen und den Output des eigenen Modells zu visualisieren.\n"], "metadata": {"id": "-GVrlEzF5a61"}}, {"cell_type": "code", "source": ["# Make the server and content run\n", "!pip install jinja2==3.0.1\n", "!pip install itsdangerous==2.0.1\n", "!pip install flask==0.12.2 \n", "\n", "#restart runtime\n", "import os\n", "def restart_runtime():\n", "  os.kill(os.getpid(), 9)\n", "\n", "!gdown 1_dBKubiLHGqRnDq5sWc0VAx5gb5TDcNM\n", "!unzip static\n", "!mkdir debug"], "metadata": {"id": "5PxBQ_L28FEJ"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import os, sys, json, re\n", "import uuid\n", "\n", "import numpy as np\n", "import cv2\n", "\n", "from flask import Flask, request\n", "from flask import send_from_directory\n", "\n", "from PIL import Image, ImageOps\n", "from io import BytesIO\n", "import base64\n", "\n", "from google.colab.output import eval_js\n", "\n", "import torch\n", "from torchvision import transforms\n", "\n", "SAVE_IMAGES = True\n", "\n", "transform = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.), \n", "                                ])\n", "\n", "site_access = eval_js(\"google.colab.kernel.proxyPort(8000)\")\n", "\n", "if os.path.exists('/content/static/draw_template.js'):\n", "  with open('/content/static/draw_template.js', 'r') as f:\n", "    data = [l.replace('\u2192TOKEN\u2190', f'{site_access}hook') for l in f.readlines()]\n", "  with open('/content/static/draw.js', 'w') as f:\n", "      f.writelines(data)\n", "  \n", "print(site_access)\n", "\n", "def convert_from_image_to_cv2_grey(img: Image) -> np.ndarray:\n", "    return np.array(img)[:,:,3]\n", "\n", "def process_image(img, blur_fact, sid, object_class, brush_size, save=True):\n", "  img = img.copy()\n", "  if blur_fact != 0:\n", "    img = cv2.GaussianBlur(img, (blur_fact,blur_fact), cv2.BORDER_DEFAULT)\n", "\n", "  img = cv2.resize(img, (28,28))\n", "  if save:\n", "    fn = f'debug/{object_class}_{brush_size}px_gb{blur_fact}_{sid}.png'\n", "    cv2.imwrite(fn, img)\n", "    return fn, img\n", "  else:\n", "    return \"\", img\n", "\n", "app = Flask(__name__, static_folder='/content/static')\n", "@app.route(\"/\", methods=['GET'])\n", "def base_app():\n", "  return send_from_directory(\"static\", \"index.html\")\n", "\n", "# Static files (compiled JS/CSS, etc.)\n", "@app.route(\"/<path:path>\")\n", "def home(path):\n", "    return send_from_directory('static', path)\n", "\n", "@app.route('/hook/<int:object_class>/<int:brush_size>', methods=['POST'])\n", "def save_canvas(object_class, brush_size):\n", "    image_data = re.sub('^data:image/.+;base64,', '', request.form['imageBase64'])\n", "    im = Image.open(BytesIO(base64.b64decode(image_data)))\n", "\n", "    sid = uuid.uuid4()\n", "\n", "    im_cv = convert_from_image_to_cv2_grey(im)\n", "\n", "    saved_files, imgs = zip(*[process_image(im_cv, blur, sid, object_class, brush_size, save=SAVE_IMAGES) for blur in [0, 11, 21]])\n", "\n", "    \n", "    model_in = transform(imgs[-1])[None,:]\n", "    model_out =  model(model_in)\n", "    model_out = model_out.flatten()\n", "\n", "\n", "    #res_scores = torch.nn.Softmax(dim=0)(torch.randn(10))\n", "    res_scores = torch.nn.Softmax(dim=0)(model_out)\n", "\n", "    res = {\n", "        'success': True,\n", "        'result': {str(i):e.item() for i,e in enumerate(res_scores)},\n", "        'files': [f for f in\n", "                  saved_files if f],\n", "    }\n", "    return json.dumps(res), 200, {'ContentType': 'application/json'}\n", "\n", "app.run(host='localhost', port=8000)"], "metadata": {"id": "c69W5Mej8SnM"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.4 (PyTorch)** | Es sind mittlerweile viele Netzwerkarchitekturen bekannt, die einfach trainiert werden und auch ohne Pre-Training gute Ergebnisse erzielen k\u00f6nnen.\n", "\n", "Eine dieser Architekturen ist die ResNet-Architektur. Eine Anpassung von ResNet18 auf MNIST gibt es unter anderem [hier](https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet18-mnist.ipynb).\n", "\n", "Trainieren und testen Sie das Modell auf der Website oder mit dem Code-Block am Anfang der \u00dcbung. Nutzen Sie eine GPU Runtime."], "metadata": {"id": "K2QQnu8193M9"}}, {"cell_type": "code", "source": ["model = None # ResNet18"], "metadata": {"id": "2u23wnKGRfTV"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.5 (PyTorch)** | Verwendung von vortrainierten Netzen. Alle gr\u00f6\u00dferen Frameworks, auch PyTorch, stellen eine Auswahl an vortrainierten Netzen zur Verf\u00fcgung. Das Training dieser Netze erfolgt auf sehr gro\u00dfen und diversen Datens\u00e4tzen und erzeugt dadurch einen sehr guten und generalisierenden Feature-Detector. F\u00fcr eigene Probleme muss meist nur der letzte Fully-Connected Layer neu trainiert werden.\n", "\n", "Erstellen Sie sich ein ResNet50 und trainieren Sie dies. Nutzen Sie eine GPU Runtime. Testen Sie das Modell auf der Website oder mit dem Code-Block am anfang der \u00dcbung."], "metadata": {"id": "frbSx5ZCQIol"}}, {"cell_type": "code", "source": ["model = None #ResNet50"], "metadata": {"id": "AbHZROrlRrcM"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Script zum Trainieren\n", "import tqdm\n", "import numpy as np\n", "import pandas as pd\n", "import plotly.express as px\n", "import torch\n", "from torch import nn, optim\n", "import torch.nn.functional as F\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms\n", "from torchvision.models import resnet50, ResNet50_Weights\n", "\n", "BATCH_SIZE = 128\n", "EPOCHS = 1\n", "LEARNING_RATE = 0.001\n", "\n", "\n", "transform = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.), \n", "                                transforms.RandomAffine(degrees=15, translate=(0.2,0.2), scale=(0.8, 1.2)),\n", "                                transforms.ColorJitter(brightness=0.2, saturation=0.99)\n", "                                ])\n", "\n", "transform_test = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.),\n", "                                ])\n", "\n", "target_transform = transforms.Compose([transforms.Lambda(lambda x:torch.LongTensor([x])),\n", "                                transforms.Lambda(lambda x: (F.one_hot(x, num_classes = 10).float().flatten(),x))\n", "                                ])\n", "\n", "# Trainingsdaten herunterladen + Transformation anwenden\n", "train_set = datasets.MNIST('./data', download=True, train=True, transform=transform, target_transform=target_transform)\n", "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n", "\n", "# Testdaten herunterladen + Transformation anwenden\n", "test_set = datasets.MNIST('./data', download=True, train=False, transform=transform_test, target_transform=target_transform)\n", "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n", "\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "\n", "EPOCHS = 5\n", "torch.manual_seed(123)\n", "\n", "model.to(device)\n", "\n", "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n", "\n", "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n", "loss_fn = nn.CrossEntropyLoss()\n", "\n", "all_losses = []\n", "progress_bar = tqdm.tqdm(range(EPOCHS), leave=False)\n", "\n", "# Epochen durchlaufen\n", "for epoch in progress_bar:\n", "    losses_train = []\n", "    \n", "    total_train = 0\n", "    model.train()\n", "    # Modell trainieren\n", "    for inputs_train, (target_train_oh, target_train) in train_loader:\n", "        inputs_train = inputs_train.to(device)\n", "        target_train_oh = target_train_oh.to(device)\n", "        target_train = target_train.to(device)\n", "        optimizer.zero_grad()\n", "        y_train = model(inputs_train)\n", "        loss = loss_fn(y_train, target_train_oh)\n", "\n", "        loss.backward()\n", "        \n", "        optimizer.step()\n", "        \n", "        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n", "        \n", "        losses_train.append(loss.item())\n", "        total_train += target_train.size(0)\n", "\n", "    # Modell testen\n", "    with torch.no_grad():\n", "        model.eval()\n", "        correct_test = 0\n", "        total_test = 0\n", "        losses_test = []\n", "        for inputs_test, (target_test_oh, target_test) in test_loader:\n", "          inputs_test = inputs_test.to(device)\n", "          target_test_oh = target_test_oh.to(device)\n", "          target_test = target_test.to(device)\n", "          y_test = model(inputs_test)\n", "          _, target_pred = torch.max(y_test.data, 1)\n", "          total_test += target_test.size(0)\n", "          correct_test += (target_pred == target_test.flatten()).sum().item()\n", "          loss_test = loss_fn(y_test, target_test_oh)\n", "\n", "          losses_test.append(loss_test.item())\n", "\n", "    epoch_loss = sum(losses_train) / total_train\n", "    epoch_loss_test = sum(losses_test) / total_test\n", "    acc_test = 100.0 * correct_test / total_test\n", "    lr = optimizer.param_groups[-1]['lr']\n", "    scheduler.step(epoch_loss_test)\n", "\n", "    all_losses.append([epoch, epoch_loss, epoch_loss_test,acc_test,lr])\n", "\n", "\n", "# Ergebnisse anzeigen\n", "df_loss = pd.DataFrame(np.array(all_losses), columns=['epoch', 'loss_train', 'loss_test','acc_test','lr'])\n", "\n", "fig = px.line(df_loss, x='epoch', y=['loss_train','loss_test'], width=850, height=500, log_y=True)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"loss\",\n", ")\n", "fig.show()\n", "\n", "fig = px.line(df_loss, x='epoch', y=['acc_test'], width=850, height=500)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"acc\",\n", ")\n", "fig.show()\n", "\n", "fig = px.line(df_loss, x='epoch', y=['lr'], width=850, height=500, log_y=True)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"learning_rate\",\n", ")\n", "fig.show()"], "metadata": {"id": "Beci419Ub1bz"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.save(model, 'good.pt')"], "metadata": {"id": "rCVpiOSKcTZv"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.6 (PyTorch)** | Ergebnisse sollten sich durch die Verwendung von vortrainierten Modellen schon deutlich verbessert haben. F\u00fcr manche Anwendungsf\u00e4lle ist dies immer noch nicht ausreichend und Sie m\u00fcssen auf diesen spezifischen Daten nachtrainieren. Die Website erlaubt, gezeichnete Bilder abzuspeichern, um sie f\u00fcr ein weiteres Training zu verwenden.\n", "\n", "\n", "Erzeugte Daten k\u00f6nnen zum Training, aber auch zum Testen verwendet werden.\n", "\n", "Folgendes ist anzupassen:\n", "1. `SAVE_IMAGES = True`\n", "2. Durch den Class-Slider l\u00e4sst das Label des Bildes festlegen\n", "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAAAWCAYAAACFbNPBAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAANzSURBVHhe7ZrfS1NhGMe/peahQiWh0YydiUFEhbvSKyeS17HwooGgg/4A8U66kOGFjG6koJtunEEwL6ThTTfC0Lt5pZRBkGyTXJxAMCk4BWLvc3w3z3E729mycNvzgeH747zbi7zf9/u8z3su6Lp+BIZhinJR/mUYpggsEIYpQdkQa//nb2xm9qB91426q11Br9qJjiuXjDrD1DO2AiFhvF77jJX3WdliZfi+G2P+WywUpq4pKpBPXw8QebuJvR+/ZEtxOq+2YupRL27faJMtDFNfFJxByDmciIOgZ+hZGsMw9UiBg7x499E2rLLjzrUjPPBwtrjWaG5uhsfjgaqqaGlpka1ngYbYqIrQEpUDiG7HEOwyOmoOi0DICcZerslaZbx60of2y2f5T2b+NYeHh9A0DZlMBgMDA5WLZFcs/J4Q4rKKkSgyb4JwySqQRESZg/ccCERbDEIdlzMtmKc9lhCLslXV8uHLviwxtUJTUxPcbrfhICSSiliPQBHi8K3pEJvs8cfhovvviLmqywFk5DwzD+NQZ5OyszQWgeRSudXw7aD8mYU5n7hcLuzs7MiaM5IrYQQWMpjqkw0VQLu5oij5T3BRkz0CciVTn2JZyBS6mfqUiPCocogxz8MIT+TEqyGxLJxkJuFgLF8UMlWhIbUF+Lqr8wvX49iJ6+ir8I3P5xdrcuGUKz3tlz2C9XmE7q6axk7B1GtDGumlALxGiEchn4r0xCrC2EBq13igJBaB0CVgtVxva5Ulptagcwgd1p1Di04Wq4HCs7wLDFoWq7cngLBftBcLgbq8CMwMOnSOUxjOROchvSLXswiEbsir5d7NDlliagU6pGezWeP8QecQ53jhHQE2UqbQyDFiF/eLkCfvErSbn5B3l+HEsYBGY8KvJF1BxIwxQ0gY4hL1si5Ac40j5E9jUpfJgt2UkKQP3Q4SB5zmbWD+Ks1LLuDfKJPCLZLFMjJfcQRk23F2CTbfQ+MTGLIJpZKzChLD5R3B+I3tyXy4RuMGIUI1c/hmQ4FAKNU7uZB0dFFI0G363Hg/v3LSiBgiMe3/+fQpLWwKncyc3IcYC3RGNk9HEd0Sh+Zn1Ge+PzmGnCYnAEuqlph2tsgJ6286H8evmjBMCYoKhOCXFRmmhEBykFD4dXemUSkrEIZpZPiikGFKwAJhGFuAP2IMrHUtcOcrAAAAAElFTkSuQmCC)\n", "3. Durch den folgenden Button k\u00f6nnen Zeichnungen direkt mit verschiedenen Strichst\u00e4rken abgespeichert werden:\n", "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIMAAAAuCAYAAAALH6pWAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAARXSURBVHhe7Zy/SiNRFMa/3YcISIhYCRYWSQSLQPodNGjlvoB/0BBsJMUiLMgWwUbElagvsFZKXMZeSLGgsbAQrCTDIOQJ7HbPnblz5k9iHJPssonnBxfJvczk3rnf+c65IfHD8/PzbwgC8VH/FQQRg+AjYhAYEYPAiBgERsQgMG1HS8uycHx8jIeHB90jjBqTk5NYWVlBKpXSPS5tYtje3kYmk0E+n9c9wqhxdXWFRqOBnZ0d3ePSliaUI4gQRhu1v52cX2oGgRExCIyIQWBEDAIjYhAYEYPAiBgERsQgMCIGgRExCMw7F0MLZ6tJJJNu22/o7mHj6QzLeg3J5D5udPdb6UEMN9jnN3bb8nlLjw0n5Qsbtm2jlNEdROt8ObTGZHIZZ096sBuhjaG2ekaSCxAaj3nPiGjb7ju2iBOav319AEN39UKPzmDg4Np9gGoC2EgPb1R1Y6vmrtFpJ1gc0/3d8DbGabc4QBE/+NlQIM2YMPjZGTBn4keyJ1qnHS0iofsHRf9pYiwHYw64a2qdNvaR3LvBzZ6vYl8oEYV3jZqI40TGQuJT7xkY63admttg0A7Z9X4WrJ8GUlpErfMqKltrLKrWLxMmKqgH1uI6UlzHGCz9i+GpDpMWbMwGdLpbQD2vFXxRRuVIbboSQhrmp1tWd22qiLT3MNWmzRQxHVD/yYJ3TxVRFtZ0v23XgHkvoui+R3e+U4WuoytPw/e0N7N6JAa0jl5E5KeYAu6+f+PNtx7JFSbcL5SoYEk/rqG2FQikV6jM67lQ+xtO3KMYTBRn9MQc24tY6NwBPnv5N1PSlqaipIy1wEZl82Xgvum4gxMlZMvBvM006hQ/FRT0g1APuYI7NJ3oSWB8yp1Pp9olNWG4D/GNjpBYOPEFROIrkzDC98+i9IK4/GtvYVymI9dZjjtWJygoXrw2mpISWDzy5kJNBdj84N2j/5ohbi7tl1D+Dr9vdtPt+4YvrlgCG88bk6+7Y9HUFIsschTBb4c2cbUM89FyXilhmhsFWKuee7XQvAemxwOuGodMDhRGA6f/NBGbFFJzFVQ5SpS9V2B8yjmFUGKWUs1utbPax1I0VnjVGp2NVxW1dpsQyqFUhP8kh9JdsaEUVt2NpMJYNYNeo04NzhppG3Oe+zV+oEhuya+JODWDU3vMGcgNOAj/oRiU1dUwTScP1+rTKE7V/PyuqvCLaT/9UGN7dcaUNfpjfoRHjroqbX31Ku1IwUrpBRclivPXCR0tO6XCFwgfSdMBFyCcdcBPd/NAzY4zn/A60pcGbv/CaaLtC7FLS0s4PDzUr0Yd9ZDdDetYqwwbThGuCu3XBba+vo7T01P9yuUfOoPwvyNiILz0M7QfnHmfpdDR3NRdvfDOxRA+sg1tqgh96hmvJuqEOIPAiBgERsQgMCIGgRExCIyIQWDaxKB+u69+si2MLmp/1T5HkX/W8Q6J/c86hPeL1AwCI2IQGBGDwIgYBA3wB2cVNOQxRDjEAAAAAElFTkSuQmCC) \n", "4. Erzeugte Daten m\u00fcssen zu einem Datenset zusammengefasst werden. Das nachfolgende Skript kann dabei helfen. Am Anfang dieser \u00dcbung wird ein auf gleiche Weise gebauter Datensatz geladen."], "metadata": {"id": "iYWIPj5RR6lX"}}, {"cell_type": "code", "source": ["from glob import glob\n", "import cv2\n", "import copy\n", "from tqdm import tqdm\n", "\n", "all_files = [(cv2.imread(i, 0), int(i.split('_')[0][-1]), i.split('_')[1], i.split('_')[2]) for i in glob('debug/*.png')]\n", "\n", "data = {}\n", "entry = {'imgs': [], 'label': []}\n", "\n", "\n", "for imgs, label, px, smooth in tqdm(all_files):\n", "  k = f'{px}_{smooth}'\n", "  if k not in data:\n", "    data[k] = copy.deepcopy(entry)\n", "  data[k]['imgs'].append(imgs)\n", "  data[k]['label'].append(label)\n", "\n", "for k in tqdm(data.keys()):\n", "  data[k]['imgs'] = np.array(data[k]['imgs'])\n", "  data[k]['label'] = np.array(data[k]['label'])\n", "\n", "\n", "np.savez_compressed(f'your_custom_data', **data)"], "metadata": {"id": "qGFfp4JnTgGn"}, "execution_count": null, "outputs": []}]}