{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["kxrUseR_X-ci"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Übung 9** Programmierung mit Python mit Anwendungen aus dem Maschinellen Lernen\n","\n"],"metadata":{"id":"tO4WGLA7VZuQ"}},{"cell_type":"markdown","source":["## Aufgabe 1\n","Heute sollen Sie selbst ein Neuronales Netz auf dem MNIST Fashion Datensatz trainieren.\n","Sie kennen den MNIST Fashion Datensatz bereits aus Übung 5."],"metadata":{"id":"kxrUseR_X-ci"}},{"cell_type":"markdown","source":["**Aufgabe 1.1 (PyTorch)** | One-Hot-Encoding ist ein Verfahren zur Darstellung von Kategorien oder diskreten Variablen als Vektoren mit binären Werten. Bei der Verwendung von One-Hot-Encoding wird jeder eindeutigen Kategorie ein binärer Wert zugeordnet. Der Vektor besteht aus Nullen, außer an der Position, die der Indexnummer der entsprechenden Kategorie entspricht, wo der Wert 1 ist.\n","\n","Schreiben Sie eine Funktion, die eine Liste von Kategorien (strings) bekommt und ein One-Hot-Encodings zurückgibt. \n","\n","```\n","Beispiel:\n","Input:\n","[               [ \n","  rot,            [1,0,0],\n","  grün,           [0,1,0],\n","  rot,     →      [1,0,0], \n","  blau,           [0,0,1],\n","  grün,           [0,1,0],\n","  rot             [1,0,0]\n","]               ]\n","```\n"],"metadata":{"id":"Y4QEJ0eqKxJ5"}},{"cell_type":"code","source":["import numpy as np\n","\n","categories = [\"mango\",\"apple\",\"mango\",\"blueberry\",\"blueberry\",\"mango\",\"peach\",\"apple\",\"mandarin\",\"orange\",\"grapefruit\",\"bananas\",\"grapefruit\",\"mandarin\",\"mango\",\"bananas\",\"mandarin\",\"pear\",\"peach\",\"lime\",\"pear\",\"orange\",\"orange\",\"apple\",\"pear\",\"lime\",\"grapefruit\",\"orange\",\"mango\",\"apple\",\"grapefruit\",\"bananas\",\"apple\",\"mandarin\",\"mango\",\"lime\",\"grapefruit\",\"lime\",\"grapefruit\",\"orange\",\"apple\",\"bananas\",\"peach\",\"blueberry\",\"peach\",\"bananas\",\"bananas\",\"mango\",\"blueberry\",\"blueberry\",\"lime\",\"grapefruit\",\"apple\",\"pear\",\"peach\",\"lime\",\"mandarin\",\"grapefruit\",\"orange\",\"peach\",\"apple\",\"apple\",\"peach\",\"peach\",\"lime\",\"mandarin\",\"orange\",\"bananas\",\"bananas\",\"peach\",\"bananas\",\"mango\",\"mango\",\"pear\",\"grapefruit\",\"blueberry\",\"bananas\",\"pear\",\"grapefruit\",\"blueberry\",\"apple\",\"mango\",\"apple\",\"lime\",\"mandarin\",\"mango\",\"lime\",\"apple\",\"grapefruit\",\"orange\",\"peach\",\"blueberry\",\"bananas\",\"pear\",\"bananas\",\"lime\",\"blueberry\",\"pear\",\"lime\",\"pear\",\"lime\",\"lime\",\"peach\",\"lime\",\"orange\",\"apple\",\"apple\",\"orange\",\"mandarin\",\"orange\",\"orange\",\"grapefruit\",\"mango\",\"bananas\",\"pear\",\"lime\",\"orange\",\"mandarin\",\"blueberry\",\"peach\",\"blueberry\",\"mandarin\",\"pear\",\"mango\",\"bananas\",\"grapefruit\",\"mango\",\"blueberry\",\"bananas\",\"grapefruit\",\"blueberry\",\"pear\",\"peach\",\"blueberry\",\"pear\",\"mandarin\",\"mandarin\",\"mango\",\"apple\",\"mandarin\",\"mandarin\",\"orange\",\"peach\",\"pear\",\"orange\",\"blueberry\",\"grapefruit\",\"mandarin\",\"pear\",\"peach\"]\n","\n","category_dictionary = {v:i for i,v in enumerate(set(categories))}\n","print(category_dictionary)\n","category_indices = [category_dictionary[cat] for cat in categories]\n","print(category_indices)\n","one_hot = np.zeros((len(categories), len(category_dictionary)))\n","one_hot[np.arange(len(categories)), category_indices] = 1\n","print(one_hot)\n"],"metadata":{"id":"RngznQFQKw8a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685625899644,"user_tz":-120,"elapsed":1094,"user":{"displayName":"kav labor","userId":"07714224401121029264"}},"outputId":"d168c089-c271-47af-8fcd-b40b152c5f8c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["{'orange': 0, 'peach': 1, 'pear': 2, 'grapefruit': 3, 'apple': 4, 'bananas': 5, 'lime': 6, 'mango': 7, 'blueberry': 8, 'mandarin': 9}\n","[7, 4, 7, 8, 8, 7, 1, 4, 9, 0, 3, 5, 3, 9, 7, 5, 9, 2, 1, 6, 2, 0, 0, 4, 2, 6, 3, 0, 7, 4, 3, 5, 4, 9, 7, 6, 3, 6, 3, 0, 4, 5, 1, 8, 1, 5, 5, 7, 8, 8, 6, 3, 4, 2, 1, 6, 9, 3, 0, 1, 4, 4, 1, 1, 6, 9, 0, 5, 5, 1, 5, 7, 7, 2, 3, 8, 5, 2, 3, 8, 4, 7, 4, 6, 9, 7, 6, 4, 3, 0, 1, 8, 5, 2, 5, 6, 8, 2, 6, 2, 6, 6, 1, 6, 0, 4, 4, 0, 9, 0, 0, 3, 7, 5, 2, 6, 0, 9, 8, 1, 8, 9, 2, 7, 5, 3, 7, 8, 5, 3, 8, 2, 1, 8, 2, 9, 9, 7, 4, 9, 9, 0, 1, 2, 0, 8, 3, 9, 2, 1]\n","[[0. 0. 0. ... 1. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 1. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n"]}]},{"cell_type":"markdown","source":["**Aufgabe 1.2 (PyTorch)** | Schreiben Sie die `SoftMax` Funktion in NumPy.\n","Die `SoftMax` Funktion wird häufig als letzte Aktivierungsfunktion zur Normalisierung der Ausgabe eines neuronalen Netzes auf eine Wahrscheinlichkeitsverteilung über vorhergesagte Ausgabeklassen verwendet.\n","\n","Mit den `SoftMax` Ausgaben lässt sich die Differenz zu One-Hot-Vektoren berechnen. Die `SoftMax` Funktion und die Differenzbildung sind ableitbar, eine wesentliche Voraussetzung für das Trainieren von Modellen mit gradientenbasierten Verfahren.\n","\n","Testen Sie, dass die Gesamtsumme der Wahrscheinlichkeiten `1` beträgt.\n","\n","Plotten Sie die Werte.\n"],"metadata":{"id":"AuoQUI2OV86i"}},{"cell_type":"code","source":["softmax_inputs = np.array([0.3,4,2,1])\n","x = np.arange(softmax_inputs.size)"],"metadata":{"id":"nqO3YN-mDL9d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Aufgabe 1.3 (PyTorch)** | Trainieren Sie ein Neuronales Netz auf dem MNIST Fashion Datensatz analog zum Video Tutorial der Übung.\n","Ein zu erwartendes Ergebnis auf den Testdaten sind $>87\\%$ Genauigkeit (Accuracy).\n","\n","Mögliche Schritte:\n","1. Designen und erzeugen Sie sich ein Modell, achten Sie auf die Hinweise im Video zu Ausgangsschichten und SoftMax.\n","2. Wählen Sie einen Optimierer und eine Loss-Funktion.\n","3. Trainieren und evaluieren Sie ihr Modell.\n","   Vergleichen Sie auch die erreichte Genauigkeit auf Test und Trainingsdaten.\n","   Weicht diese stark ab, z.B. Genauigkeit auf den Trainingsdaten $96\\%$, Genauigkeit auf den Testdaten $69\\%$, liegt eine \n","   Überanpassung des Netzes (Overfitting) vor.\n","   Mögliche Gründe:\n","   - Überbestimmtheit des Netzes, zu viele Parameter\n","   - Testdaten sind nicht repräsentativ\n","   - Training über zu viele Epochen"],"metadata":{"id":"xGPfWl4SDEwv"}},{"cell_type":"code","source":["import tqdm\n","import numpy as np\n","import pandas as pd\n","import plotly.express as px\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","BATCH_SIZE = 100\n","EPOCHS = 15\n","\n","# ToTensor(): Wandelt die Daten in Tensoren um\n","# Normalize((0.5,), (0.5,)): Normiert die Daten um den Mittelwert 0.5\n","# Lambda(lambda x: torch.flatten(x)): Erzeugt aus 2D Bildern (28x28 px), 1D Vektoren mit 784 Werten\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,)),\n","                                transforms.Lambda(lambda x: torch.flatten(x))])\n","\n","# Trainingsdaten herunterladen + Transformation anwenden\n","train_set = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Testdaten herunterladen + Transformation anwenden\n","test_set = datasets.FashionMNIST('./data', download=True, train=False, transform=transform)\n","test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# TODO Modell erzeugen\n","\n","# TODO Optimierer und Loss Funktion auswählen\n","\n","# Epochen durchlaufen\n","for epoch in EPOCHS:\n","  pass\n","  # TODO Modell trainieren\n","  # TODO Modell testen\n","\n","# TODO Ergebnisse anzeigen\n"],"metadata":{"id":"V17cI7vYDVmC"},"execution_count":null,"outputs":[]}]}