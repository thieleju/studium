{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "collapsed_sections": ["kxrUseR_X-ci"]}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "markdown", "source": ["# **\u00dcbung 8** Programmierung mit Python mit Anwendungen aus dem Maschinellen Lernen\n", "\n"], "metadata": {"id": "tO4WGLA7VZuQ"}}, {"cell_type": "markdown", "source": ["[Einf\u00fchrung Neuronale Netze](https://playground.tensorflow.org/)\n", "- Data Pattern (linear, nicht-linear trennbar)\n", "- Datenset (Noise, Train/Test-Split)\n", "- Epoche\n", "- Aktivierungsfunktionen (Linear, TanH)\n", "- Auswirkungen der Learning Rate\n", "- Design Netzwerk (Gr\u00f6\u00dfe, Breite)\n", "- Overfitting\n", "- Stabilit\u00e4t des Trainings"], "metadata": {"id": "3l-kRbTmAIjZ"}}, {"cell_type": "markdown", "source": ["## Aufgabe 1\n", "Die erste Aufgabe besch\u00e4ftigt sich mit der Lineare Regression in PyTorch."], "metadata": {"id": "kxrUseR_X-ci"}}, {"cell_type": "code", "source": ["# Hilfsfunktionen\n", "\n", "import plotly.express as px\n", "import plotly.graph_objects as go\n", "from matplotlib import cm\n", "from matplotlib.ticker import LinearLocator\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "\n", "SAMPLES_PER_AXIS = 100\n", "\n", "def _generate_dataset(n, m, t, s, e, with_noise=True):\n", "    x1 = np.tile(np.linspace(s, e, SAMPLES_PER_AXIS), SAMPLES_PER_AXIS)\n", "    x2 = np.repeat(np.linspace(s, e, SAMPLES_PER_AXIS), SAMPLES_PER_AXIS)\n", "    r = np.sin(x1)*np.sin(x2)*3 + (np.random.random(SAMPLES_PER_AXIS*SAMPLES_PER_AXIS)-0.5)*15 if with_noise else np.zeros_like(x1)\n", "    y = n*x1 + m*x2 + t + r\n", "\n", "    return pd.DataFrame(np.vstack([x1, x2, y, r]).T, columns=['x1', 'x2', 'y', 'r'])\n", "\n", "\n", "def generate_dataset(n, m, t):\n", "    ''' f(x1,x1) = n*x1 + m*x2 + t'''\n", "\n", "    train = _generate_dataset(n, m, t, 0, 50)\n", "    test = _generate_dataset(n, m, t, 50, 200, with_noise=False)\n", "\n", "    return train, test\n", "\n", "\n", "def show_dataset(dl, title):\n", "    SAMPLES_PER_AXIS1 = SAMPLES_PER_AXIS* int(len(dl) / (SAMPLES_PER_AXIS*SAMPLES_PER_AXIS))\n", "    rs = lambda x: x.values.reshape(SAMPLES_PER_AXIS1,SAMPLES_PER_AXIS)\n", "\n", "    data = [go.Surface(z=rs(dl['y']),x=rs(dl['x1']),y=rs(dl['x2']), surfacecolor=rs(dl['r'])) for ds in dl]\n", "    fig = go.Figure(data=data)\n", "\n", "    fig.update_layout(\n", "        title=title, \n", "        autosize=True, \n", "        )\n", "    \n", "    fig.update_scenes(xaxis_title_text='x1',  \n", "                  yaxis_title_text='x2',  \n", "                  zaxis_title_text='y')\n", "\n", "    fig.show()"], "metadata": {"id": "yf-HM4EbQ2q0"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.1 (PyTorch)** | Gegeben ist ein Datensatz mit zwei Input-Parameters $x1$ und $x2$ und einem gemessenen Output-Parameter $y$\n", "Es ist bekannt, dass sich $y$ durch folgende Funktion bestimmt ist: $f(x1,x2) = nx1 + mx2 + t + r(x1,x2)$\n", "\n", "$r(x1,x2)$ \u00fcberlagert die lineare Funktion mit einem gleichverteilten, periodischen Rauschen.\n", "\n", "Mithilfe einer Linearen Regression sollen f\u00fcr unbekannte $x1, x2$ paare $y$-Werte abgesch\u00e4tzt werden. Im Folgenden soll eine Lineare Regression mit PyTorch durchgef\u00fchrt werden. Sie k\u00f6nnen sich an den Inhalten im Videomaterial zu dieser \u00dcbung orientieren.\n", "\n", "Schauen Sie sich den gegebenen Datensatz an, der Code hierf\u00fcr ist schon vorgegeben.\n"], "metadata": {"id": "AuoQUI2OV86i"}}, {"cell_type": "code", "source": ["generated_train_df, generated_test_df = generate_dataset(n=2, m=-1, t=60)\n", "show_dataset(generated_train_df, title='[Train] Noisy Linear Surface') \n", "show_dataset(generated_test_df, title='[Test] Flat Linear Surface')\n", "show_dataset(pd.concat([generated_train_df, generated_test_df], ignore_index=True), title='[Train+Test] Combined') \n", "\n", "\n", "label_train_df = generated_train_df.pop(\"y\")\n", "generated_train_df.pop(\"r\")\n", "label_test_df = generated_test_df.pop(\"y\")\n", "_ = generated_test_df.pop(\"r\")\n", "\n"], "metadata": {"id": "lJZ_HqiNUU64"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.2 (PyTorch)** | Zun\u00e4chst soll der Datensatz in Tensoren konvertiert werden.\n", "Erzeugen Sie sich die vier Variablen `X_train, y_train, X_test, y_test`\n", "\n", "```\n", "Erwartete Ausgabe der gegebenen Prints:\n", "X_train torch.Size([10000, 2]) torch.float32 cpu\n", "y_train torch.Size([10000, 1]) torch.float32 cpu\n", "X_test  torch.Size([10000, 2]) torch.float32 cpu\n", "y_test  torch.Size([10000, 1]) torch.float32 cpu\n", "```"], "metadata": {"id": "dIFTBLPmAYrw"}}, {"cell_type": "code", "source": ["import torch\n", "import torch.nn as nn\n", "import numpy as np\n", "\n", "### ADD CODE HERE\n", "\n", "print(\"X_train\", X_train.shape, X_train.dtype, X_train.device)\n", "print(\"y_train\", y_train.shape, y_train.dtype, y_train.device)\n", "print(\"X_test \", X_test.shape, X_test.dtype, X_test.device)\n", "print(\"y_test \", y_test.shape, y_test.dtype, y_test.device)"], "metadata": {"id": "VsFepfSP8n6d"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.3 (PyTorch)** | Erzeugen Sie ein Modell, welches die Parameter $n,m,t$ als trainierbare Parameter enth\u00e4lt. Sie k\u00f6nnen hierf\u00fcr die Funktion selbst modellieren oder das `torch.nn.Linear`-Modul verwenden.\n", "\n", "Weisen Sie das Modell der Variablen `model` zu.\n", "\n"], "metadata": {"id": "MW-tkOz37vo6"}}, {"cell_type": "code", "source": ["### ADD CODE HERE"], "metadata": {"id": "zFAWhgZ_9Z0N"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.4 (PyTorch)** | Als n\u00e4chstes muss eine geeignete Loss-Funktion f\u00fcr dieses Problem ausgew\u00e4hlt werden. Die Loss-Funktion ist ein Ma\u00df f\u00fcr den Grad der Abweichung zwischen den vorhergesagten Ausgaben des Modells und den tats\u00e4chlichen Ausgaben.\n", "\n", "Die Distanz, zwischen vorhergesagten und tats\u00e4chlichen Wert, k\u00f6nnte hier ein gutes Ma\u00df sein. Im Namespace `torch.nn` sind verschiedene Loss-Funktionen definiert. W\u00e4hlen Sie eine aus, oder implementieren Sie diese selbst.\n", "\n", "Weisen Sie die Loss-Funktion der Variablen `loss_fn` zu. "], "metadata": {"id": "HXnZArA99nL4"}}, {"cell_type": "code", "source": ["### ADD CODE HERE"], "metadata": {"id": "71JPz7f_9g-G"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.5 (PyTorch)** | Als letztes muss ein Optimizer erstellt werden. Ein Optimizer ist ein Algorithmus, der verwendet wird, um die Parameter eines Modells auf der Grundlage der Ergebnisse der Loss-Funktion zu optimieren. Erstellen Sie eine Instanz von `torch.optim.SGD` (stochastic gradient descent). Diesem m\u00fcssen Sie die Modellparameter `model.parameters()` und eine `learning_rate` \u00fcbergeben. \n", "\n", "Die `learning_rate` gibt an, wie stark die Parameter durch die Gradienten beeinflusst werden. Hier gilt es, ein richtiges Ma\u00df zu finden."], "metadata": {"id": "-EQFKcQsCLnK"}}, {"cell_type": "code", "source": ["learning_rate = 0.0006\n", "optimizer = None # CHOOSE AN OPTIMIZER\n"], "metadata": {"id": "UALNAtAdDBxl"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.6 (PyTorch)** | Trainieren Sie das erstellte Modell. In der Regel wird das Modell pro Epoche einmal mit allen Trainingsdaten trainiert. Folgende Schritte sollen in jeder Epoche durchgef\u00fchrt werden.\n", "1. Modellausgaben `y_pred_train`, mit Trainingsdaten `X_train`, erzeugen\n", "2. Berechnen des Loss `loss_train` durch Vergleich von `y_pred_train` und `y_train`\n", "3. Den Gradienten auf Basis des Loss berechnen\n", "4. Modellparameter optimieren\n", "5. Modellausgaben `y_pred_test`, mit Testdaten `X_test`, erzeugen\n", "6. Berechnen des Loss `loss_test` durch Vergleich von `y_pred_test` und `y_test`\n", "7. Gradienten zur\u00fccksetzen\n", "\n", "\n", "Vergleichen Sie die Modellparameter $n,m,t$\n"], "metadata": {"id": "6VRgvkgXOAA6"}}, {"cell_type": "code", "source": ["loss_res = []\n", "\n", "num_epochs = 25000\n", "plot_freq = 10\n", "print_freq = 100\n", "\n", "for epoch in range(num_epochs):\n", "\n", "  # ADD CODE HERE\n", "\n", "  if (epoch+1) % plot_freq == 0:\n", "    loss_res.append([epoch, loss_train.item(), loss_test.item()])\n", "\n", "  if (epoch+1) % print_freq == 0:\n", "    print(f'epoch: {epoch+1}, loss_train = {loss_train.item():.4f}, loss_test = {loss_test.item():.4f}')\n", "\n", "df = pd.DataFrame(np.array(loss_res), columns=['epoch', 'loss_test', 'loss_train'])\n", "\n", "fig = px.line(df, x=\"epoch\", y=['loss_test', 'loss_train'], title='Trainingsverlauf', log_y=True)\n", "fig.show()"], "metadata": {"id": "jmVAPI66DBbT"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.7 (PyTorch)** | Abschlie\u00dfend sollen Sie versuchen, das obige Beispiel durch einfache Ver\u00e4nderungen deutlich schneller Trainieren zu.\n", "\n", "Dazu k\u00f6nnten folgende ver\u00e4ndert werden.\n", "- `learning_rate` anpassen\n", "- anderen Optimierer testen, z.B. Adam\n", "- Input normieren\n", "- Ver\u00e4ndern Sie auch den Parameter $t$"], "metadata": {"id": "Pm8qLMrkRjcV"}}, {"cell_type": "code", "source": ["# F\u00fchren Sie \u00c4nderungen oben im Code durch oder erstellen Sie sich eine neue Zelle."], "metadata": {"id": "Ydmayj8tRK5h"}, "execution_count": null, "outputs": []}]}