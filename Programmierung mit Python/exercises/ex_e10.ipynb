{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4", "collapsed_sections": ["uzuArThzB58Q", "wZeFhy-CJPQQ"]}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "source": ["# **\u00dcbung 10** Programmierung mit Python mit Anwendungen aus dem Maschinellen Lernen\n"], "metadata": {"id": "C_hRVXAwByn_"}}, {"cell_type": "markdown", "source": ["## Aufgabe 1\n", "\n", "Heute sollen Sie wieder selbst ein Neuronales Netz trainieren. Diesmal soll ein faltendes neuronales Netz (Convolutional Neural Network - CNN) verwendet werden.\n", "\n", "In \u00dcbung 9 war es nicht einfach, mit einem Netz aus vollst\u00e4ndig verbundenen Schichten \u00fcber $92\\%$ Genauigkeit auf den Testdaten zu kommen. Selbst mit einfachen CNN's sind Genauigkeiten ab $94\\%$ m\u00f6glich, dies k\u00f6nnen Sie gerne nach dieser \u00dcbung selbst pr\u00fcfen."], "metadata": {"id": "uzuArThzB58Q"}}, {"cell_type": "markdown", "source": ["**Aufgabe 1.1 (CNN)** | Was machen CNN's \u00fcberhaupt? Diese \u00dcbung soll mit einer kleinen Veranschaulichung beginnen.\n", "\n", "Das CNN, das Sie gleich selbst trainieren sollen, hat mehrere Convolutional Layer. Der erste Layer besteht aus mehreren (3x3) Filternkerneln, die gelernt werden sollen, um Informationen aus dem Bild zu extrahieren.\n", "\n", "Gegeben ist der Code, der **einen** der Filterkernel des ersten Layer beispielhaft \u00fcber ein Eingabebild faltet. Das Netz lernt die Filtermasken selbst, hier ist die Filtermaske eines Sobel-Filters gegeben.\n", "\n", "F\u00fchren Sie den Code aus, und pr\u00fcfen Sie ihr Verst\u00e4ndnis dieser Operation. Vergewissern Sie sich au\u00dferdem, dass Sie folgende Begriff im Zusammenhang mit CNN's und MaxPooling verstanden haben:\n", "- Padding\n", "- Stride\n", "- Gr\u00f6\u00dfe/Kernel-Size\n"], "metadata": {"id": "n6Ch-aPsExwM"}}, {"cell_type": "code", "source": ["# Download kreis.png\n", "!gdown 1ggeDwwGKAhnEh8ixKPqWok1rxA1NH4NC"], "metadata": {"id": "XvQYWA2UbZH0"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%matplotlib inline\n", "import cv2\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "\n", "img = cv2.imread('kreis.png')\n", "img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "img_grey = img_grey.astype(np.float32)/255.\n", "\n", "\n", "sobel_x_filter = np.array([[1, 0, -1], \n", "                   [2, 0, -2], \n", "                   [1, 0, -1]])\n", "\n", "img_flt = cv2.filter2D(img_grey, -1, sobel_x_filter)\n", "\n", "img_flt = img_flt * (img_flt > 0) # ReLu\n", "img_flt = img_flt/np.max(img_flt) # Normierung 0-1 zur Anzeige\n", "\n", "plt.subplot(1, 2, 1)\n", "plt.imshow(img_grey, cmap=plt.get_cmap('gray'))\n", "plt.title(\"Input\")\n", "\n", "\n", "plt.subplot(1, 2, 2)\n", "plt.imshow(img_flt, cmap=plt.get_cmap('gray'))\n", "plt.title(\"Filtered\")\n", "\n", "plt.show()"], "metadata": {"id": "X8nLtqAMGY8v"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 1.2 (CNN)** | Schreiben Sie den Code f\u00fcr die Funktion `max_pool_2d` mit NumPy Funktionen, die eine 2D MaxPooling Operation durchf\u00fchrt. Stride und Gr\u00f6\u00dfe sollen dabei `(2,2)` betragen. Gehen Sie davon aus, dass die Dimensionen des Inputs `x` gerade sind.\n", "```\n", "Erwartete Ausgabe:\n", "[[ 7  9 11]\n", " [19 21 23]\n", " [31 33 35]]\n", " ```"], "metadata": {"id": "qK9gMXsbIQHH"}}, {"cell_type": "code", "source": ["x = np.arange(36).reshape((6,6))\n", "\n", "def max_pool_2d(x):\n", "    ### ADD YOUR CODE HERE ###\n", "    pass\n", "\n", "print(x)\n", "print(max_pool_2d(x))"], "metadata": {"id": "Bl6PeUz1IJxA"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## Aufgabe 2\n", "\n", "**Aufgabe 2.0 (PyTorch)** | Zun\u00e4chst ist wieder ein Datensatz vorgegeben. Zur sp\u00e4teren veranschaulichung kommt der normale MNIST Datensatz (Klassifikation Zahlen 0-9) zum Einsatz."], "metadata": {"id": "wZeFhy-CJPQQ"}}, {"cell_type": "code", "source": ["!pip install imshowtools"], "metadata": {"id": "Wh5aqI5ZbFdf"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import tqdm\n", "import numpy as np\n", "import pandas as pd\n", "import plotly.express as px\n", "import torch\n", "from torch import nn, optim\n", "import torch.nn.functional as F\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms\n", "from imshowtools import imshow as multi_imshow\n", "\n", "BATCH_SIZE = 128\n", "BATCH_NORM = False\n", "EPOCHS = 12\n", "LEARNING_RATE = 0.001\n", "\n", "trans_scale = transforms.Lambda(lambda x: x/255.) if BATCH_NORM else transforms.Normalize((0.5,), (0.5,))\n", "\n", "transform = transforms.Compose([transforms.ToTensor(),\n", "                                trans_scale, \n", "                                ])\n", "\n", "transform_test = transforms.Compose([transforms.ToTensor(),\n", "                                trans_scale,\n", "                                ])\n", "\n", "target_transform = transforms.Compose([transforms.Lambda(lambda x:torch.LongTensor([x])),\n", "                                transforms.Lambda(lambda x: (F.one_hot(x, num_classes = 10).float().flatten(),x))\n", "                                ])\n", "\n", "# Trainingsdaten herunterladen + Transformation anwenden\n", "train_set = datasets.MNIST('./data', download=True, train=True, transform=transform, target_transform=target_transform)\n", "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n", "\n", "# Testdaten herunterladen + Transformation anwenden\n", "test_set = datasets.MNIST('./data', download=True, train=False, transform=transform_test, target_transform=target_transform)\n", "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n", "\n", "data,(labels_one_hot,labels) = next(iter(test_loader))\n", "\n", "print(data.size(),labels_one_hot.size())\n", "\n", "scale_fn = lambda x: x*255 if BATCH_NORM else x/2 + 0.5\n", "\n", "multi_imshow(*scale_fn(data[:20].resize(20,28,28,1))) "], "metadata": {"id": "V49kTKhfbHvh"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 2.1 (PyTorch)** | Erstellen Sie ein CNN Modell analog zum Video.\n", "Unsere Bilder haben eine Eingangsgr\u00f6\u00dfe von `(28, 28, 1)` statt `(32, 32, 3)` wie im Video.\n", "\n", "Verwenden Sie f\u00fcr die erste Schicht eine Filtergr\u00f6\u00dfe von `3` und ein Padding  von `1`. **(Optional)** Lesen Sie auch \u00fcber [BatchNorm](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) und bauen Sie diesen Layer nach jeder Faltung ein, bei der Verwendung k\u00f6nnen sie den Parameter `BATCH_NORM` auf `True` setzen.\n", "\n", "Erwartete Genauigkeit auf den Testdaten: $98\\%$\n", "\n"], "metadata": {"id": "XI-C7r1qLz6j"}}, {"cell_type": "code", "source": ["class ConvNet(nn.Module):\n", "  def __init__(self):\n", "    super(ConvNet, self).__init__()\n", "    ### ADD YOUR CODE HERE ###\n", "    pass\n", "\n", "  def forward(self, x):\n", "    ### ADD YOUR CODE HERE ###\n", "    pass"], "metadata": {"id": "HiKcr-DzK6bq"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["**Aufgabe 2.2 (PyTorch)** | Der Trainingscode aus der letzten \u00dcbung ist gegeben. Hier k\u00f6nnen Sie auch ihren eigenen Code verwenden, zusammen mit dem vorher definierten Modell.\n", "\n", "Wenn Sie mit der Advanced \u00dcbung weitermachen wollen, speichern Sie sich das erzeugte Modell ab:\n", "\n", "```\n", "model_scripted = torch.jit.script(model) # Export to TorchScript\n", "model_scripted.save('YOUR_MODEL.pt') # Save\n", "```\n"], "metadata": {"id": "34KOnXg0nI8q"}}, {"cell_type": "code", "source": ["import tqdm\n", "import numpy as np\n", "import pandas as pd\n", "import plotly.express as px\n", "import torch\n", "from torch import nn, optim\n", "import torch.nn.functional as F\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms\n", "from torchvision.models import resnet50, ResNet50_Weights\n", "\n", "\n", "\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "\n", "torch.manual_seed(12)\n", "# Modell erstellen\n", "model = ConvNet()\n", "model.to(device)\n", "\n", "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n", "\n", "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n", "loss_fn = nn.CrossEntropyLoss()\n", "\n", "all_losses = []\n", "progress_bar = tqdm.tqdm(range(EPOCHS), leave=False)\n", "\n", "# Epochen durchlaufen\n", "for epoch in progress_bar:\n", "    losses_train = []\n", "    \n", "    total_train = 0\n", "    model.train()\n", "    # Modell trainieren\n", "    for inputs_train, (target_train_oh, target_train) in train_loader:\n", "        inputs_train = inputs_train.to(device)\n", "        target_train_oh = target_train_oh.to(device)\n", "        target_train = target_train.to(device)\n", "        optimizer.zero_grad()\n", "        y_train = model(inputs_train)\n", "        loss = loss_fn(y_train, target_train_oh)\n", "\n", "        loss.backward()\n", "        \n", "        optimizer.step()\n", "        \n", "        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n", "        \n", "        losses_train.append(loss.item())\n", "        total_train += target_train.size(0)\n", "\n", "    # Modell testen\n", "    with torch.no_grad():\n", "        model.eval()\n", "        correct_test = 0\n", "        total_test = 0\n", "        losses_test = []\n", "        for inputs_test, (target_test_oh, target_test) in test_loader:\n", "          inputs_test = inputs_test.to(device)\n", "          target_test_oh = target_test_oh.to(device)\n", "          target_test = target_test.to(device)\n", "          y_test = model(inputs_test)\n", "          _, target_pred = torch.max(y_test.data, 1)\n", "          total_test += target_test.size(0)\n", "          correct_test += (target_pred == target_test.flatten()).sum().item()\n", "          loss_test = loss_fn(y_test, target_test_oh)\n", "\n", "          losses_test.append(loss_test.item())\n", "\n", "    epoch_loss = sum(losses_train) / total_train\n", "    epoch_loss_test = sum(losses_test) / total_test\n", "    acc_test = 100.0 * correct_test / total_test\n", "    lr = optimizer.param_groups[-1]['lr']\n", "    scheduler.step(epoch_loss_test)\n", "\n", "    all_losses.append([epoch, epoch_loss, epoch_loss_test,acc_test,lr])\n", "\n", "\n", "# Ergebnisse anzeigen\n", "df_loss = pd.DataFrame(np.array(all_losses), columns=['epoch', 'loss_train', 'loss_test','acc_test','lr'])\n", "\n", "fig = px.line(df_loss, x='epoch', y=['loss_train','loss_test'], width=850, height=500, log_y=True)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"loss\",\n", ")\n", "fig.show()\n", "\n", "fig = px.line(df_loss, x='epoch', y=['acc_test'], width=850, height=500)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"acc\",\n", ")\n", "fig.show()\n", "\n", "fig = px.line(df_loss, x='epoch', y=['lr'], width=850, height=500, log_y=True)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"learning_rate\",\n", ")\n", "fig.show()"], "metadata": {"id": "Beci419Ub1bz"}, "execution_count": null, "outputs": []}]}