{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4", "collapsed_sections": ["ioftjZi_IKm4"]}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "accelerator": "GPU", "gpuClass": "standard"}, "cells": [{"cell_type": "markdown", "source": ["# **\u00dcbung 9a** Programmierung mit Python mit Anwendungen aus dem Maschinellen Lernen\n", "\n"], "metadata": {"id": "UJ7KPVQtKZwq"}}, {"cell_type": "markdown", "source": ["## Aufgabe 1\n", "Diese \u00dcbung baut auf der Basis\u00fcbung auf und soll M\u00f6glichkeiten aufzeigen, wie Sie Ihr neuronales Netz noch effizienter trainieren k\u00f6nnen. Der Datensatz und ein Basismodell sind bereits vorgegeben.\n", "\n", "Versuchen Sie das Modell weiter zu verbessern\n", "(Effizienz + Genauigkeit).\n", "\n", "Ver\u00e4ndern Sie dabei nicht die Anzahl der Parameter, die Anzahl der Layer und behalten sie die LinearLayer bei.\n", "\n", "M\u00f6gliche Bereiche zur Verbesserung:\n", "- Allgemeine Verbesserung\n", " - Optimizer\n", " - Aktivierungsfunktionen\n", " - Dynamisches anpassen der Learning Rate\n", " - Batch Size anpassen\n", " - Gewichte initialisieren\n", " - Mehrmals mit denselben Parametern, aber verschiedenen Seeds trainieren.\n", "- Overfitting mitigieren\n", " - Regularization\n", " - Batchnorm\n", " - Dropout\n", "\n"], "metadata": {"id": "ioftjZi_IKm4"}}, {"cell_type": "code", "source": ["!pip install imshowtools"], "metadata": {"id": "fxFvOOkoyyfn"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import tqdm\n", "import numpy as np\n", "import pandas as pd\n", "import plotly.express as px\n", "import torch\n", "from torch import nn, optim\n", "import torch.nn.functional as F\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms\n", "from imshowtools import imshow as multi_imshow\n", "\n", "BATCH_SIZE = 100\n", "EPOCHS = 20\n", "LEARNING_RATE = 0.001\n", "\n", "transform = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.),\n", "                                transforms.RandomAffine(degrees=5, translate=(0.1,0.1), scale=(0.9, 1.1)),\n", "                                transforms.ColorJitter(brightness=0.2, saturation=0.99),  \n", "                                transforms.Lambda(lambda x: torch.flatten(x))\n", "                                ])\n", "\n", "transform_test = transforms.Compose([transforms.ToTensor(),\n", "                                transforms.Lambda(lambda x: x/255.),\n", "                                transforms.Lambda(lambda x: torch.flatten(x))\n", "                                ])\n", "\n", "target_transform = transforms.Compose([transforms.Lambda(lambda x:torch.LongTensor([x])),\n", "                                transforms.Lambda(lambda x: (F.one_hot(x, num_classes = 10).float().flatten(),x))\n", "                                ])\n", "\n", "# Trainingsdaten herunterladen + Transformation anwenden\n", "train_set = datasets.FashionMNIST('./data', download=True, train=True, transform=transform, target_transform=target_transform)\n", "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n", "\n", "# Testdaten herunterladen + Transformation anwenden\n", "test_set = datasets.FashionMNIST('./data', download=True, train=False, transform=transform_test, target_transform=target_transform)\n", "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n", "\n", "data,(labels_one_hot,labels) = next(iter(test_loader))\n", "\n", "print(data.size(),labels_one_hot.size())\n", "\n", "multi_imshow(*data[:20].resize(20,28,28,1)*255)#, cmap='binary')\n"], "metadata": {"id": "d19jZ53_qWxu"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import tqdm\n", "import numpy as np\n", "import pandas as pd\n", "import plotly.express as px\n", "import torch\n", "from torch import nn, optim\n", "import torch.nn.functional as F\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms\n", "\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "\n", "# Modell\n", "class Model(nn.Module):\n", "    def __init__(self, n_features, hidden1, hidden2, n_out):\n", "        super(Model, self).__init__()\n", "        self.linear1 = nn.Linear(n_features, hidden1)\n", "        self.linear2 = nn.Linear(hidden1, hidden2)\n", "        self.linear3 = nn.Linear(hidden2, n_out)\n", "\n", "    def forward(self, x):\n", "        y1 = F.sigmoid(self.linear1(x))\n", "        y2 = F.sigmoid(self.linear2(y1))\n", "        y3 = self.linear3(y2)\n", "        return y3\n", "\n", "# Modell erstellen\n", "model = Model(784,500,250,10) \n", "model.to(device)\n", "\n", "# Optimierer und Loss Funktion ausw\u00e4hlen\n", "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n", "loss_fn = nn.CrossEntropyLoss()\n", "\n", "all_losses = []\n", "progress_bar = tqdm.tqdm(range(EPOCHS), leave=False)\n", "\n", "# Epochen durchlaufen\n", "for epoch in progress_bar:\n", "    losses_train = []\n", "    losses_test = []\n", "    total_train = 0\n", "    # Modell trainieren\n", "    for inputs_train, (target_train_oh, target_train) in train_loader:\n", "        inputs_train = inputs_train.to(device)\n", "        target_train_oh = target_train_oh.to(device)\n", "        target_train = target_train.to(device)\n", "        optimizer.zero_grad()\n", "        y_train = model(inputs_train)\n", "        loss = loss_fn(y_train, target_train_oh)\n", "\n", "        loss.backward()\n", "        \n", "        optimizer.step()\n", "        \n", "        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n", "        \n", "        losses_train.append(loss.item())\n", "        total_train += target_train.size(0)\n", "\n", "    # Modell testen\n", "    with torch.no_grad():\n", "        correct_test = 0\n", "        total_test = 0\n", "        for inputs_test, (target_test_oh, target_test) in test_loader:\n", "          inputs_test = inputs_test.to(device)\n", "          target_test_oh = target_test_oh.to(device)\n", "          target_test = target_test.to(device)\n", "          y_test = model(inputs_test)\n", "          _, target_pred = torch.max(y_test.data, 1)\n", "          total_test += target_test.size(0)\n", "          correct_test += (target_pred == target_test.flatten()).sum().item()\n", "          loss_test = loss_fn(y_test, target_test_oh)\n", "\n", "          losses_test.append(loss_test.item())\n", "\n", "    epoch_loss = sum(losses_train) / total_train\n", "    epoch_loss_test = sum(losses_test) / total_test\n", "    acc_test = 100.0 * correct_test / total_test\n", "    lr = optimizer.param_groups[-1]['lr']\n", "\n", "    all_losses.append([epoch, epoch_loss, epoch_loss_test,acc_test,lr])\n", "\n", "\n", "# Ergebnisse anzeigen\n", "df_loss = pd.DataFrame(np.array(all_losses), columns=['epoch', 'loss_train', 'loss_test','acc_test','lr'])\n", "\n", "fig = px.line(df_loss, x='epoch', y=['loss_train','loss_test'], width=850, height=500, log_y=True)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"loss\",\n", ")\n", "fig.show()\n", "\n", "fig = px.line(df_loss, x='epoch', y=['acc_test'], width=850, height=500)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"acc\",\n", ")\n", "fig.show()\n", "\n", "fig = px.line(df_loss, x='epoch', y=['lr'], width=850, height=500, log_y=True)\n", "fig.update_layout(\n", "    xaxis_title=\"epoch\",\n", "    yaxis_title=\"learning_rate\",\n", ")\n", "fig.show()"], "metadata": {"id": "BQZjwaFqeDH_"}, "execution_count": null, "outputs": []}]}